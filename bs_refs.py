from urllib.request import Request, urlopen
from bs4 import BeautifulSoup
import certifi


def wallarm_refs(cve_id: str):
	refs = []
	req = Request(
		url=f'https://lab.wallarm.com/?s={cve_id}',
		headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
	)
	html = urlopen(req, cafile=certifi.where()).read()
	soup = BeautifulSoup(html, 'lxml')
	ref_card = soup.find_all('div', class_="read-more")
	for ref in ref_card:
		links = ref.find_all('a', href=True)
		refs.append(str(links).split('"')[1])

	if refs:
		return refs
	else:
		return None


def imperva_refs(cve_id: str):
	refs = []
	req = Request(
		url=f'https://www.imperva.com/blog/?s={cve_id}',
		headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
	)
	html = urlopen(req, cafile=certifi.where()).read()
	soup = BeautifulSoup(html, 'lxml')
	ref_card = soup.find_all('a', class_="subtitle-card dotted")
	for ref in ref_card:
		sub_card_dot = str(ref).split('"')[3]
		if sub_card_dot[0:5] == "https":
			refs.append(sub_card_dot)
		else:
			pass

	if refs:
		return refs
	else:
		return None

def fedora_refs(cve_id: str):
	refs = []
	url_prefix = "https://lists.fedoraproject.org"
	req = Request(
		url=f'https://lists.fedoraproject.org/archives/search?mlist=package-announce%40lists.fedoraproject.org&q={cve_id}',
		headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
	)
	html = urlopen(req, cafile=certifi.where()).read()
	soup = BeautifulSoup(html, 'lxml')
	ref_card = soup.find_all('span', class_="thread-title")
	for ref in ref_card:
		url_postfix = str(ref.find_all('a', href=True)).split('"')[1]
		refs.append(url_prefix + url_postfix)

	if refs:
		return refs
	else:
		return None


def ubuntu_refs(cve_id: str):
	refs = []
	req = Request(
		url=f'https://ubuntu.com/search?q={cve_id}',
		headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
	)
	html = urlopen(req, cafile=certifi.where()).read()
	soup = BeautifulSoup(html, 'lxml')
	ref_card = soup.find_all('h5')
	for ref in ref_card:
		url = str(ref.find_all('a', href=True)).split('"')[3]
		refs.append(url)

	if refs:
		return refs
	else:
		return None


def osv_refs(cve_id: str):
	refs = []
	prefix = "https://osv.dev"
	req = Request(
		url=f'https://osv.dev/list?ecosystem=&q={cve_id}',
		headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
	)
	html = urlopen(req, cafile=certifi.where()).read()
	soup = BeautifulSoup(html, 'lxml')
	ref_card = soup.find_all('span', class_="vuln-table-cell mdc-data-table__cell")
	for ref in ref_card:
		postfix = str(ref.find_all('a', href=True)).split('"')[1]
		refs.append(prefix + postfix)

	if refs:
		return refs
	else:
		return None


def github_refs(cve_id: str):
	refs = []
	prefix = "https://github.com"
	req = Request(
		url=f'https://github.com/advisories?query={cve_id}',
		headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
	)
	html = urlopen(req, cafile=certifi.where()).read()
	soup = BeautifulSoup(html, 'lxml')
	ref_card = soup.find_all('div', class_="lh-condensed flex-auto")
	for ref in ref_card:
		postfix = str(ref.find_all('a', href=True)).split('"')[5]
		refs.append(prefix + postfix)

	if refs:
		return refs
	else:
		return None

